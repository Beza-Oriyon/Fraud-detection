{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4b1ca0",
   "metadata": {},
   "source": [
    "Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  # Alternative if XGBoost issues\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, f1_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d6bd4",
   "metadata": {},
   "source": [
    "Load Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dc74cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151112, 16)\n",
      "class\n",
      "0    0.906354\n",
      "1    0.093646\n",
      "Name: proportion, dtype: float64\n",
      "Train shape: (120889, 15) Fraud rate: 0.09364789186774644\n",
      "Test shape: (30223, 15) Fraud rate: 0.09363729609899746\n"
     ]
    }
   ],
   "source": [
    "# Load r processed e-commerce data\n",
    "data = pd.read_csv('../data/processed/processed_fraud_data.csv')  \n",
    "\n",
    "print(data.shape)\n",
    "print(data['class'].value_counts(normalize=True))  # Confirm imbalance\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Fraud rate:\", y_train.mean())\n",
    "print(\"Test shape:\", X_test.shape, \"Fraud rate:\", y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f270fd6",
   "metadata": {},
   "source": [
    "Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dfabc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC-PR: 0.6507\n",
      "F1-Score: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     27393\n",
      "           1       0.90      0.51      0.65      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.93      0.75      0.81     30223\n",
      "weighted avg       0.95      0.95      0.94     30223\n",
      "\n",
      "[[27231   162]\n",
      " [ 1374  1456]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob_lr)\n",
    "auc_pr_lr = auc(recall, precision)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"AUC-PR: {auc_pr_lr:.4f}\")\n",
    "print(f\"F1-Score: {f1_lr:.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca218da",
   "metadata": {},
   "source": [
    "Ensemble Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226649f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "AUC-PR: 0.7046\n",
      "F1-Score: 0.6130\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     27393\n",
      "           1       0.56      0.68      0.61      2830\n",
      "\n",
      "    accuracy                           0.92     30223\n",
      "   macro avg       0.76      0.81      0.78     30223\n",
      "weighted avg       0.93      0.92      0.92     30223\n",
      "\n",
      "[[25858  1535]\n",
      " [  901  1929]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),  # Handles imbalance\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision_x, recall_x, _ = precision_recall_curve(y_test, y_prob_xgb)\n",
    "auc_pr_xgb = auc(recall_x, precision_x)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(f\"AUC-PR: {auc_pr_xgb:.4f}\")\n",
    "print(f\"F1-Score: {f1_xgb:.4f}\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8b9ca",
   "metadata": {},
   "source": [
    "Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190d4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison:\n",
      "Logistic Regression - AUC-PR: 0.6507, F1: 0.6547\n",
      "XGBoost - AUC-PR: 0.7046, F1: 0.6130\n",
      "Best model saved to ../models/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison:\")\n",
    "print(f\"Logistic Regression - AUC-PR: {auc_pr_lr:.4f}, F1: {f1_lr:.4f}\")\n",
    "print(f\"XGBoost - AUC-PR: {auc_pr_xgb:.4f}, F1: {f1_xgb:.4f}\")\n",
    "\n",
    "# Select best (XGBoost usually wins on imbalanced data)\n",
    "best_model = xgb_model  # Change to lr_model if LR better (unlikely)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "print(\"Best model saved to ../models/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ad8a4",
   "metadata": {},
   "source": [
    "## Cross-Validation for Reliable Performance Estimation\n",
    "Using StratifiedKFold (k=5) to preserve class distribution in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8309065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (XGBoost)\n",
      "AUC-PR: 0.7154 ± 0.0056\n",
      "F1-Score: 0.6206 ± 0.0055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import auc, precision_recall_curve, f1_score\n",
    "\n",
    "# Prepare data (already have X, y)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_pr_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train XGBoost on fold\n",
    "    model_cv = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=(y_train_fold == 0).sum() / (y_train_fold == 1).sum(),\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model_cv.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_prob_val = model_cv.predict_proba(X_val_fold)[:, 1]\n",
    "    y_pred_val = model_cv.predict(X_val_fold)\n",
    "    \n",
    "    # Metrics\n",
    "    precision, recall, _ = precision_recall_curve(y_val_fold, y_prob_val)\n",
    "    auc_pr_scores.append(auc(recall, precision))\n",
    "    f1_scores.append(f1_score(y_val_fold, y_pred_val))\n",
    "\n",
    "print(\"Cross-Validation Results (XGBoost)\")\n",
    "print(f\"AUC-PR: {np.mean(auc_pr_scores):.4f} ± {np.std(auc_pr_scores):.4f}\")\n",
    "print(f\"F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6d9d9",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV\n",
    "Tuning key XGBoost parameters for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184be59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   3.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   4.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   3.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   4.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   4.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   3.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=  12.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=   5.9s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=   6.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   4.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   4.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   1.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   3.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   4.2s\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best CV AUC-PR score: 0.7227094503139928\n",
      "Tuned model Test AUC-PR: 0.7078\n",
      "Tuned model Test F1: 0.6094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95     27393\n",
      "           1       0.54      0.70      0.61      2830\n",
      "\n",
      "    accuracy                           0.92     30223\n",
      "   macro avg       0.75      0.82      0.78     30223\n",
      "weighted avg       0.93      0.92      0.92     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Smaller, safe grid\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=10  # ~1:10 imbalance ratio\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    scoring='average_precision',  # optimizes AUC-PR\n",
    "    cv=3,\n",
    "    n_jobs=1,        # <<< Prevents TerminatedWorkerError on Windows\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# This is the important line — make sure it finishes!\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV AUC-PR score:\", grid_search.best_score_)\n",
    "\n",
    "# Now create the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Optional: retrain on full training data (already done by best_estimator_)\n",
    "# Evaluate on test set to confirm\n",
    "from sklearn.metrics import auc, precision_recall_curve, f1_score, classification_report\n",
    "\n",
    "y_prob = best_xgb.predict_proba(X_test)[:, 1]\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "print(f\"Tuned model Test AUC-PR: {auc(recall, precision):.4f}\")\n",
    "print(f\"Tuned model Test F1: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb5ab4",
   "metadata": {},
   "source": [
    "Retrain final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5afa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Test AUC-PR: 0.7078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/best_tuned_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params['scale_pos_weight'] = 10  # Keep if not in grid\n",
    "best_params['random_state'] = 42\n",
    "\n",
    "final_model = XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test\n",
    "from sklearn.metrics import auc, precision_recall_curve, f1_score\n",
    "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "print(f\"Tuned Test AUC-PR: {auc(recall, precision):.4f}\")\n",
    "\n",
    "# Save\n",
    "joblib.dump(final_model, '../models/best_tuned_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9866bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model saved!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_xgb, '../models/best_tuned_model.pkl')\n",
    "print(\"Tuned model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
