{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4b1ca0",
   "metadata": {},
   "source": [
    "Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  # Alternative if XGBoost issues\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, f1_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d6bd4",
   "metadata": {},
   "source": [
    "Load Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc74cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151112, 16)\n",
      "class\n",
      "0    0.906354\n",
      "1    0.093646\n",
      "Name: proportion, dtype: float64\n",
      "Train shape: (120889, 15) Fraud rate: 0.09364789186774644\n",
      "Test shape: (30223, 15) Fraud rate: 0.09363729609899746\n"
     ]
    }
   ],
   "source": [
    "# Load r processed e-commerce data\n",
    "data = pd.read_csv('../data/processed/processed_fraud_data.csv')  \n",
    "\n",
    "print(data.shape)\n",
    "print(data['class'].value_counts(normalize=True))  # Confirm imbalance\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Fraud rate:\", y_train.mean())\n",
    "print(\"Test shape:\", X_test.shape, \"Fraud rate:\", y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f270fd6",
   "metadata": {},
   "source": [
    "Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dfabc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC-PR: 0.6507\n",
      "F1-Score: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     27393\n",
      "           1       0.90      0.51      0.65      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.93      0.75      0.81     30223\n",
      "weighted avg       0.95      0.95      0.94     30223\n",
      "\n",
      "[[27231   162]\n",
      " [ 1374  1456]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob_lr)\n",
    "auc_pr_lr = auc(recall, precision)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"AUC-PR: {auc_pr_lr:.4f}\")\n",
    "print(f\"F1-Score: {f1_lr:.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca218da",
   "metadata": {},
   "source": [
    "Ensemble Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226649f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "AUC-PR: 0.7046\n",
      "F1-Score: 0.6130\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     27393\n",
      "           1       0.56      0.68      0.61      2830\n",
      "\n",
      "    accuracy                           0.92     30223\n",
      "   macro avg       0.76      0.81      0.78     30223\n",
      "weighted avg       0.93      0.92      0.92     30223\n",
      "\n",
      "[[25858  1535]\n",
      " [  901  1929]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),  # Handles imbalance\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision_x, recall_x, _ = precision_recall_curve(y_test, y_prob_xgb)\n",
    "auc_pr_xgb = auc(recall_x, precision_x)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(f\"AUC-PR: {auc_pr_xgb:.4f}\")\n",
    "print(f\"F1-Score: {f1_xgb:.4f}\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8b9ca",
   "metadata": {},
   "source": [
    "Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190d4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison:\n",
      "Logistic Regression - AUC-PR: 0.6507, F1: 0.6547\n",
      "XGBoost - AUC-PR: 0.7046, F1: 0.6130\n",
      "Best model saved to ../models/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison:\")\n",
    "print(f\"Logistic Regression - AUC-PR: {auc_pr_lr:.4f}, F1: {f1_lr:.4f}\")\n",
    "print(f\"XGBoost - AUC-PR: {auc_pr_xgb:.4f}, F1: {f1_xgb:.4f}\")\n",
    "\n",
    "# Select best (XGBoost usually wins on imbalanced data)\n",
    "best_model = xgb_model  # Change to lr_model if LR better (unlikely)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "print(\"Best model saved to ../models/best_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
